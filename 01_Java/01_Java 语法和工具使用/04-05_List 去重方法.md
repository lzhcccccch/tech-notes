# List 去重方法

[toc]

## 常见去重方法

### 使用 HashSet 去重

```java
public class ListDeduplication {
    // 方法1：基础 HashSet 去重
    public static <T> List<T> deduplicateWithHashSet(List<T> list) {
        return new ArrayList<>(new HashSet<>(list));
    }

    // 方法2：保持原顺序的 LinkedHashSet 去重
    public static <T> List<T> deduplicateKeepOrder(List<T> list) {
        return new ArrayList<>(new LinkedHashSet<>(list));
    }
}
```

使用示例：

```java
List<String> original = Arrays.asList("A", "B", "A", "C", "B", "D");

// 使用 HashSet（不保证顺序）
List<String> deduplicated1 = deduplicateWithHashSet(original);
// 可能输出：[D, A, B, C]

// 使用 LinkedHashSet（保持原顺序）
List<String> deduplicated2 = deduplicateKeepOrder(original);
// 输出：[A, B, C, D]
```

### Stream API 去重方法

#### 使用 distinct()

```java
public class StreamDeduplication {
    // 基本 distinct 去重
    public static <T> List<T> deduplicateWithStream(List<T> list) {
        return list.stream()
                  .distinct()
                  .collect(Collectors.toList());
    }

    // 自定义比较器去重
    public static <T> List<T> deduplicateWithComparator(
        List<T> list, 
        Comparator<? super T> comparator
    ) {
        return list.stream()
                  .collect(Collectors.collectingAndThen(
                      Collectors.toCollection(() -> 
                          new TreeSet<>(comparator)),
                      ArrayList::new
                  ));
    }
}
```

#### 复杂对象去重示例

```java
public class Person {
    private String name;
    private int age;

    // 构造器、getter、setter 省略

    // 使用 Stream 去重
    public static List<Person> deduplicateByName(List<Person> persons) {
        return persons.stream()
                     .collect(Collectors.collectingAndThen(
                         Collectors.toMap(
                             Person::getName,
                             p -> p,
                             (existing, replacement) -> existing
                         ),
                         map -> new ArrayList<>(map.values())
                     ));
    }
}
```

---



## 性能比较

- `HashSet`是最快的去重方式。
- `Stream.distinct`性能较差，适用于小规模数据。

---



## 示例代码

### 基于索引的去重

```java
public class HighPerformanceDeduplication {
    public static <T> List<T> deduplicateWithIndex(List<T> list) {
        List<T> result = new ArrayList<>(list.size());
        Set<Integer> seen = new HashSet<>();
        
        for (int i = 0; i < list.size(); i++) {
            T element = list.get(i);
            int hash = System.identityHashCode(element);
            if (seen.add(hash)) {
                result.add(element);
            }
        }
        return result;
    }
}
```

### 并行流去重

```java
public class ParallelDeduplication {
    public static <T> List<T> deduplicateParallel(List<T> list) {
        return list.parallelStream()
                  .distinct()
                  .collect(Collectors.toList());
    }
    
    // 带自定义收集器的并行去重
    public static <T> List<T> deduplicateParallelCustom(List<T> list) {
        return list.parallelStream()
                  .collect(Collectors.collectingAndThen(
                      Collectors.toCollection(
                          () -> Collections.synchronizedSet(new LinkedHashSet<>())
                      ),
                      ArrayList::new
                  ));
    }
}
```

### 大数据量去重

```java
public class LargeListDeduplication {
    public static <T> List<T> deduplicateLargeList(List<T> list) {
        // 使用分片处理
        int batchSize = 10000;
        List<T> result = new ArrayList<>();
        Set<T> seen = new HashSet<>();
        
        for (int i = 0; i < list.size(); i += batchSize) {
            int end = Math.min(i + batchSize, list.size());
            List<T> batch = list.subList(i, end);
            
            batch.forEach(item -> {
                if (seen.add(item)) {
                    result.add(item);
                }
            });
        }
        return result;
    }
}
```

### 自定义对象去重

```java
public class CustomObjectDeduplication {
    public static <T> List<T> deduplicateByField(
        List<T> list, 
        Function<T, ?> keyExtractor
    ) {
        return new ArrayList<>(
            list.stream()
                .collect(Collectors.toMap(
                    keyExtractor,
                    Function.identity(),
                    (existing, replacement) -> existing
                ))
                .values()
        );
    }
}
```

---



## 总结

- 如果顺序不重要，优先使用 `HashSet` 进行去重。
- 如果需要保留顺序，使用 `LinkedHashSet`。
- 对于小规模数据，可以使用 `Stream.distinct` 简化代码。